[{"content":"I have recently had a few days off from work due to festivities in Germany and I used some of my spare time to finally investigate the Vim editor.\nFor those who do not know Vim is a text editor, which was developed by Bram Moolenaar and released for the first time in 1991. So it\u0026rsquo;s not that old yet. But if you consider the fact that this is an improved version of Billy Joy\u0026rsquo;s vi editor which was originally developed in 1976 for the UNIX operating system, things start to get interesting.\nVim for laymen If you\u0026rsquo;ve never used Vim, the first time you open it, the only question you have is how do I exit this thing that just hijacked my terminal (it\u0026rsquo;s :wq for write and quit and :q! for quit and discard changes).\nMost people, including myself barely 3 weeks ago, scratch their heads at apparent masochists that try to use Vim as of 2022, when there are such amazing editors like VSCode out there. And yes, VSCode can do everything that Vim can and probably more but because of the multimodal editing capabilities, Vim tends to be much faster with\u0026hellip; everything.\nMultimodal editing Vim does not behave like a normal editor. Yeah there is a cursor but when you start Vim it starts in Normal mode, which is basically optimal for text manipulation without the need to depart too far from the home-row keys. In normal mode, when you type, the characters are actually bound to certain commands and you will see no input appearing. Until you hit i.\ni sets Vim to Insert mode, which is basically letting you type text. This is what you know from conventional editors, where there\u0026rsquo;s a cursor, you type and text appears. When you press \u0026lt;esc\u0026gt; you go back to the Normal mode.\nThere\u0026rsquo;s also v that sets Vim to Visual mode. This mode resembles selecting with a mouse or with a Shift key, however it doesn\u0026rsquo;t require you to hold any modifier key down and you can clearly see what you\u0026rsquo;re selecting as you do it.\nWhy is this cool The fact that most text manipulation happens in Normal mode is a paradise for developers. Consider an example:\ndef blah(): print(\u0026#34;this is not indented correctly\u0026#34;) In a typical editor you would go to the second line and likely press Tab to insert a proper indent. In VSCode you could use e.g. Ctrl+G, then specify the line number, e.g. 2 and then hit Ctrl+] to indent the content to the right. That\u0026rsquo;s 3 separate steps.\nIn Vim\u0026rsquo;s Normal mode this is: \u0026gt;2gg. Super-fast.\nWhat if I had more lines to indent?\ndef blah(): print(\u0026#34;this is not indented correctly\u0026#34;) print(\u0026#34;this is not indented correctly\u0026#34;) print(\u0026#34;this is not indented correctly\u0026#34;) In VSCode I would generally go to the first problematic line with Ctrl+G, then use the arrow keys and Shift to select the two lines below and finally hit Ctrl+].\nIn Vim\u0026rsquo;s Normal mode this is: 2gg3\u0026gt;\u0026gt; (go to line 2 with gg command and then indent 3 lines with \u0026gt;\u0026gt;).\nüëâ Vim is blazingly fast for text traversal and modification. This is especially useful for software developers but also applies to any profession that requires a lot of text typing.\nVim vs. Emacs Let\u0026rsquo;s go back for a moment to the discussion about editors in general.\nThere\u0026rsquo;s a holy war going on between Vim and another editor with a rich history called Emacs. The feud reportedly is older than the Internet itself.\nHave I used Emacs? No. Am I planning to use Emacs? Also no. At least at the moment I am biased towards Vim because of it\u0026rsquo;s multimodal editing style and it\u0026rsquo;s sheer speed.\nAlso the availability plays a factor: Vim is installed by default on most Linux distros that I\u0026rsquo;ve used and works exactly the same way everywhere if you stick to vanilla Vim as much as possible. Since I often have to work with a number of different machines, having the versatility to connect e.g. via SSH and jump into Vim without having to install anything is golden.\nVim vs. VSCode So have I uninstalled VSCode and am I now just typing up everything in a little terminal window? No. And I am not going to leave VSCode behind.\nüëâ I love VSCode and I will keep on using it almost the same way I\u0026rsquo;ve been using it so far. But I\u0026rsquo;ve now installed the Vim emulation plugin in VSCode and I can enjoy the best of both worlds. I recommend it to everyone.\nVim bindings everywhere The cool part about Vim is that the bindings seem to be quite simple to port or at least emulate in many different editors. Since Vim at it\u0026rsquo;s core is basically a buffer view of a file which reacts to commands, you will find that a lot of applications that are at least somewhat developer-oriented do have Vim bindings in their offer.\nü§Ø I was mindblown by the fact that Obsidian which is my Knowledgebase Tool of choice supports Vim bindings. It\u0026rsquo;s incredible that I can use the exact same tricks for notetaking.\nVim just scales well Vim really scales. If you\u0026rsquo;re worried that there\u0026rsquo;s something Vim won\u0026rsquo;t be able to do, you probably should stop worrying. Well, it probably won\u0026rsquo;t play music and let you respond to emails like Emacs does but if you are less of a tinkerer and more of a doer, you probably wouldn\u0026rsquo;t care.\nAs a total newbie I would just learn the very basics, starting with the navigation, copy-pasting, etc. A few examples:\nh j k l act like arrow keys in Normal mode -\u0026gt; convenient, because you don\u0026rsquo;t need to reach the arrows to navigate zz centers the current line in view, zt sends it to the top zb to the bottom ^ moves the cursor to the beginning of the line while $ to the end (like RegEx) yy copies the current line, dd cuts the current line, p is for pasting after the cursor position while P is for pasting before the cursor position i sets the insert mode, I sends the cursor to the beginning of the line and sets insert mode a sets the insert mode after the cursor position, A sends the cursor to the end of the line and sets insert mode Then I would learn about registers which kind of behave like clipboards. You can cut, yank (copy) to them and paste text from them. For example:\n\u0026quot;+y copies to the system clipboard (+ register) \u0026quot;ay copies to the a register \u0026quot;ap pastes from the a register When you realize that you can chain those commands and add integer modifiers to apply the action to multiple text objects at once, it\u0026rsquo;s where the fun really begins. For example:\n\u0026quot;+5yy copies 5 consecutive lines to the system clipboard 3k moves cursor 3 lines down v3w selects 3 consecutive words Then you start working with text objects more efficiently and you discover some cool recipes to solve typical problems with text editing in software development:\n\u0026gt;i{ indents whatever is inside curly braces ya{ copies enclosing curly braces with all the content ciw''\u0026lt;esc\u0026gt;P wraps a word in quotes Finally you realize you can speed stuff up tremendously by recording macros, for example that last command from before could be recorded as a macro. For example qq will start recording to the register q. Then you can run the command as specified and press q at the end to stop recording. Press @q to use the macro anytime you want to quote something.\nü§Ø On top of that Vim supports scirpting in vimscript language and if you use a more modern distribution of Vim, like NeoVim, you can technically write plugins in any language to supercharge Vim if you really need to.\nConclusions I will be keeping Vim around for longer. I have already gotten much faster and my fingers do not need to do as much work as before to get things done. I do however fall-back onto VSCode\u0026rsquo;s default editor when I struggle to do some more advanced stuff, e.g. progressive selection of a searched pattern for which I haven\u0026rsquo;t found a terriffic equivalent in Vim. I am also not investing much time into customizing and spicying up my Vim experience, since I want to train my brain to replicate at least some of the most common command chains on the fly, whenever I need them. When in doubt I usually look up stuff in my notes.\nVim is hard. It has a very steep learning curve but if you\u0026rsquo;re already professionally developing software, you will likely understand its value if you give it an honest try over at least few days. If you care about overall speed, this is definitely a long-term investment for you to commit to, because some things might not come natural with how Vim works. I still think the commands in most cases follow some nice mnemonics and I often find talking to myself in terms of those mnemonics when I want to get something more complex done using Vim commands.\nBut above all, remember. It does not matter what editor you\u0026rsquo;re using and what plugins you\u0026rsquo;re in need of, as long as you train the awareness of what you really need to get your job done quickly and efficiently. If tools like Vim significantly speed you up, use them. If every time you use them you find yourself wondering how to do something nicely for 30 min straight, then you\u0026rsquo;re missing the point. The moment you realize you don\u0026rsquo;t know how to do something with Vim, use a different editor even if for a few minutes - don\u0026rsquo;t let a tool block you from being a performant developer.\n","permalink":"http://kjczarne.github.io/2022-07-04-i-used-vim-for-3-weeks.-heres-how-it-went/","summary":"I have recently had a few days off from work due to festivities in Germany and I used some of my spare time to finally investigate the Vim editor.\nFor those who do not know Vim is a text editor, which was developed by Bram Moolenaar and released for the first time in 1991. So it\u0026rsquo;s not that old yet. But if you consider the fact that this is an improved version of Billy Joy\u0026rsquo;s vi editor which was originally developed in 1976 for the UNIX operating system, things start to get interesting.","title":"I used Vim for 3 weeks. Here's how it went"},{"content":"Sin number 7: from nightmare import * I\u0026rsquo;ve been thinking long about which sin to name as the last in the grand seven of Python No-Nos. It finally came to me when working on one of legacy projects I\u0026rsquo;ve been contributing to (sadly this one is not open-source, so I cannot share the details).\nstar imports -\u0026gt; imports formed like the titular from nightmare import *.\nWhence the temptation? Star imports are tempting because they seem to reduce boilerplate. For example, instead of importing a number of objects from a module by importing them explicitly, you could just use a * and all available objects would be imported:\nfrom magic_module import magic_wand, magic_cape, magic_hat # vs. from magic_module import * If you\u0026rsquo;ve worked with Python for a little while you almost certainly have seen a star import somewhere.\nWhy is this a sin? While they are really nice to keep the top of the file with the import statements tidy, they are a huge pain in the neck for anybody who is supposed to read and understand your code and also might cause unnecessary namespace pollution.\nA wild object appears Why is this bad? Well, imagine that in our example from before I didn\u0026rsquo;t care much for explicitly importing stuff and just used from magic_module import *.\nNow imagine I use two of the three objects that I\u0026rsquo;ve imported before throughout the script:\nfrom magic_module import * # a lot of code here... def put_on(hat): if type(hat) == type(magic_hat): print(\u0026#34;Abracadabra\u0026#34;) else: print(\u0026#34;I am an average hat enjoyer\u0026#34;) # a lot of code here... def do_magic(): magic_wand.use() # a lot of code here... Now imagine the magic_module is not the only module I import:\nfrom magic_module import * from special_module import * from very_special_module import * from not_so_special_module import * from no_ideas_for_names_module import * Suppose you have never seen the script before and you know nothing about any of these modules. Fair enough.\nSo now, a question: where do magic_wand and magic_hat come from? Perhaps they were imported from special_module? Or perhaps not_so_special_module? Essentially in such a situation people usually rely on their IDEs to find that symbol throughout the modules but this usually costs a lot of memory, e.g. PyCharm likes to build an index of these and that\u0026rsquo;s why I never touch PyCharm for Python development, since it consumes a lot of resources. For me it was generally slow, bloated and confusing since the very beginning.\nLet\u0026rsquo;s invite everybody to the party On the flipside let\u0026rsquo;s imagine what would happen with a * import if the module you\u0026rsquo;re importing from has a lot of importable symbols. Imagine for a brief moment that you want to invite your friends to a birthday party with a Python import statement (I know it\u0026rsquo;s dumb, bear with me please):\nfrom friends import Adam, Anna, Eve, Evelyn, Derek, Fabian, Felicia, ... At some point you get tired and you\u0026rsquo;re like you know what, let\u0026rsquo;s just invite everybody:\nfrom friends import * The day of the party comes and you see an ocean of people flooding your suburban street carrying a giant birthday cake and singing Happy Birthday in a volume that\u0026rsquo;s making your house windows rattle. You were expecting 30 people, you got over 1000.\nBut how could have this happened?\nYou inspect the friends module and horrified you find that it contains:\nfrom contact_list import * You\u0026rsquo;ve invited everybody from your contact list, because the module was importing all contacts first in order to classify them as friends. Is there any way you could have avoided that?\nWell there would have been two ways. First, you could have just stopped using * imports and explicitly list all the people that were invited. But if you really for some reason wanted to still do from friends import * without the consequence of actually importing everybody, then you could have set __all__ in the friends module:\nfrom contact_list import * __all__ = [\u0026#39;Adam\u0026#39;, \u0026#39;Anna\u0026#39;, \u0026#39;Eve\u0026#39;, \u0026#39;Evelyn\u0026#39;, \u0026#39;Derek\u0026#39;, \u0026#39;Fabian\u0026#39;, \u0026#39;Felicia\u0026#39;, ...] # Note that `__all__` contains symbol _names_, not literal symbols __all__ is a nifty little module-level attribute that lets you control what symbols will be visible to other modules that import the current module. In other words, it restricts the number of symbols that are automatically exposed when doing star imports. In some way it is analogous to the export keyword from JavaScript, however here it still would be possible to explicitly import something that is not mentioned in __all__, unlike in JS.\nHow to recognize a sinner? Star imports are not necessarily the bane of my existence. Generally it is possible to figure out what comes from where but namespace pollution that often results from them (the everyone instead of friends situation) can be very painful for the users of your project. You generally don\u0026rsquo;t want the user to have access to every single implementation detail of your module and you should actually prefer to expose the bare minimum that still offers enough flexibility to get the user\u0026rsquo;s job done.\nBut\u0026hellip; I haven\u0026rsquo;t used star imports for years and I will likely never use them. I really hope you will stop using them as well after having understood the problems associated.\nHow to repent? Here\u0026rsquo;s what we should do (in my humble opinion):\nForget the existence of the star imports in our own code -\u0026gt; i.e. stop using from x import * and start using from x import y, z. Make our user-facing interface be resilient against others using the start imports -\u0026gt; i.e. modules you consider public, should have __all__ defined as a list of symbol names that you actually want the users to get, should they do from your_module import *. ","permalink":"http://kjczarne.github.io/2022-07-04-seven-sins-of-python-sin-7/","summary":"Sin number 7: from nightmare import * I\u0026rsquo;ve been thinking long about which sin to name as the last in the grand seven of Python No-Nos. It finally came to me when working on one of legacy projects I\u0026rsquo;ve been contributing to (sadly this one is not open-source, so I cannot share the details).\nstar imports -\u0026gt; imports formed like the titular from nightmare import *.\nWhence the temptation? Star imports are tempting because they seem to reduce boilerplate.","title":"Seven Sins of Python - Sin 7"},{"content":"Sin number 6: Packaging not done right Packaging Python projects properly can be truly a pain in the neck. However learning how to properly set up a package is extremely valuable because adherence to standards means more people can use your package efficiently.\nüëâ The biggest sin of all things package-related is storing Python projects as simple collections of directories.\nWhence the temptation? Python is a simple scripting lanugage so the natural tendency newcomers have is to simply create folders with a bunch of scripts and then run those folders one by one. They tend to skip thinking about how pip install is able to seemingly magically conjure foreign code out of nothingness and when they start reading on it, they claim it\u0026rsquo;s too much work to set it up properly.\nI used to be one of those people when I started out with Python. Today, I tend to freak out massively if I see Python projects that are not set up as any formal package and have some strange custom installation patterns.\nWhy is this a sin? This is predominantly sin of hubris and laziness combined, we all succumb to these sometimes. Hubris, because people often think they can come up with simpler and better packaging solutions than the entire community of Python developers combined. Laziness, because often instead of reading up on the standards, they take the path of the least resistance which often ends in extremely poor scalability.\nNot to mention the confusion other Python developers familiar with the existing toolchains will experience when looking at a codebase with a bespoke packaging solution.\nHow to recognize a sinner? The most common symptoms are easy to spot:\nNo setup.py at the Python project root Inability to pip install the package Strange instructions on how to set up and use the project (which often boil down to run main.py or something akin) Profuse usage of quasi-anti-patterns like sys.path.append How to repent? Your only way to redemption is to structure your Python package properly, i.e. you need to learn a bit about what they are and how to make them. It is actually quite simple and I\u0026rsquo;ll attempt to explain it in an easy-to-understand form.\nA Python package is a collection of modules defined in *.py files structured in such a way that lets pip package manager to install this collection and be globally used in any other script that uses a particular Python intepreter.\nüëÄ Modules are Python files and directories of Python files that contain a special __init__.py file that makes it possible to import them. Packages are just collections of modules.\nThere are a few important peculiarities about Python packages:\nA Python package is not equivalent to a single Git repo -\u0026gt; a Git repo can contain multiple Python packages at once A Python package must contain an __init__.py file in each directory to be treated as a package A Python pacakge must have a setup.py file at the root of the repository, it might contain an explicit map to Python package directory names or it might use the find_packages() function which automatically looks for packages in subdirectories Packages are described in detail in Python documentation.\nPackage structure If your package has a structure:\nX | |-\u0026gt; Y |-\u0026gt; Z |-\u0026gt; setup.py \u0026hellip; the Y and Z will be treated as packages, not X. If you want X as a package the conventional pattern is to do:\nX | |-\u0026gt; X | |-\u0026gt; Y | |-\u0026gt; Z | |-\u0026gt; setup.py ‚ö† Git Repo != Python Package. A single Git repo according to Python standards could contain multiple Python packages.\nName conflicts resulting from improper structure Suppose you have designed two packages that look like this:\nX | |-\u0026gt; Y |-\u0026gt; Z |-\u0026gt; setup.py W | |-\u0026gt; Y |-\u0026gt; Z |-\u0026gt; setup.py The way Python installs packages is by running setup.py and in setup.py you\u0026rsquo;ve usually got a find_packages() function call. If it finds any existing package named Y it will uninstall it and install the one that you just told it to install. So e.g. if you do pip install X you would actually be adding two packages named Y and Z to the list of installed packages. If you were to then do pip install W you would get a name conflict because Y and Z refer to sth that came from X and pip would resolve the conflict by removing what was previously installed and installing the new thing.\nPlease don\u0026rsquo;t use plain folders If you were to say let\u0026rsquo;s not use a Python package, just use folders. What will happen then is in every script you will have to modify the import lookup path for Python to be able to find the modules you\u0026rsquo;re trying to import. So if I want to get e.g. X/Y/modules/somescript.py from a file that is located in Z I would need to do:\nimport sys, os sys.path.append(os.path.join(os.path.dirname(__file__), \u0026#34;..\u0026#34;, \u0026#34;Y\u0026#34;)) sys.path.append(os.path.join(os.path.dirname(__file__), \u0026#34;..\u0026#34;, \u0026#34;Y\u0026#34;, \u0026#34;modules\u0026#34;)) from Y.modules import somescript Instead of doing just:\nfrom Y.modules import somescript üëÄ That\u0026rsquo;s because Python uses the sys.path list of directories to look up *.py files and load modules from. By default sys.path contains the current working directory but not the subdirectories, so you would have to add each subdirectory to the sys.path list were you not to use a standard Python package.\nüôè So please do yourself a favor and follow the standards outlined in PEP documents to not run into such strange problems. Many open-source tools doing stuff with Python packages may downright assume this structure and if you don\u0026rsquo;t follow the standard you risk on missing out on goodies as well as making the project way less maintainable.\nThe __init__.py For the find_packages() function idiomatically used in setup.py to automatically detect all the Python files belonging to a particular package, you need to add at least an empty __init__.py file at each directory level.\nüëÄ __init__.py is used as the module definition file and is the first file to be executed when you\u0026rsquo;re importing a directory-level module into any other Python script. It can be left empty or it can contain some initialization logic depending on how you want to set up your package.\nSo the proper structure for a package X with two directory-level modules Y and Z would normally look like this:\nX | |-\u0026gt; X | |-\u0026gt; Y | | |-\u0026gt; __init__.py | | | |-\u0026gt; Z | | |-\u0026gt; __init__.py | | | |-\u0026gt; __init__.py | |-\u0026gt; setup.py setup.py and setup.cfg My recommendation is to use a minimal setup.py and a second declarative configuration file named setup.cfg since it\u0026rsquo;s always easier to read a declarative file than a custom Python script. So if you can, stay with setup.py as close to this as possible:\nfrom setuptools import setup if __name__ == \u0026#34;__main__\u0026#34;: setup() Whereas your setup.cfg should be the file describing your package through-and-through. Here is an example from mkcommit:\n[metadata] name = mkcommit author = Krzysztof J. Czarnecki author_email = kjczarne@gmail.com version = attr: mkcommit.__version__ url = https://github.com/kjczarne/mkcommit description = Dead-simple tool for enforcing clean commit messages. long_description = file: README.md long_description_content_type = text/markdown keywords = git, commit, style, templates license = MIT classifiers = License :: OSI Approved :: MIT License Programming Language :: Python :: 3 Programming Language :: Python :: 3.7 [options] zip_safe = False include_package_data = True packages = find: python_requires = \u0026gt;=3.6 install_requires = InquirerPy pyperclip prettyprinter pyyaml requests [options.entry_points] console_scripts = mkcommit = mkcommit.main:main [options.extras_require] dev = pdoc flake8 twine setuptools autopep8 nox [flake8] exclude = .git, __pycache__, build, dist, .tox, .nox, .pytest_cache max_complexity = 12 max_line_length = 100 ignore = E731 E116 E114 E221 E241 Skipping the obvious stuff like author or url that points to the repo, there are a few entries that deserve an explanation:\nversion -\u0026gt; you could always store a version tag here as a literal but what I like to do is to use attr: project_name.__version__ directive. In the __init__.py that is at the root of my Python package I place a __version__ = \u0026quot;0.0.1\u0026quot; variable which I can later use from within the modules to e.g. decide what API version to use.\nüëÄ The attr: part is a directive that will try to find a particular attribute (variable) in a Python module.\nlong_description -\u0026gt; I usually use file: README.md, which is a directive that opens a README.md file at the root of the repo and will use the contents as a long description. This is exactly what you see when you inspect Python packages on PyPi.\nlong_description_content_type -\u0026gt; default format used by setuptools is RST. I prefer Markdown in most cases, so I set text/markdown. Otherwise you should prepare your README.rst file but it doesn\u0026rsquo;t look nearly as good as the Markdown variant on GitHub or GitLab.\nlicense -\u0026gt; if you\u0026rsquo;re planning to upload the package to pypi.org for everybody to use, this should be a valid open-source license name.\nclassifiers -\u0026gt; this is used by registries like pypi.org to categorize the package. Nobody ever remembers them, everybody copies them from PyPi. The License and Programming Language classifiers are the minimum required by PyPi.\nzip_safe -\u0026gt; believe it or not but Python packages can be installed in a compressed (ZIP) format that makes them a bit smaller in size and usually makes them run a tiny bit faster. Turning this on is however not recommended in larger projects since not all resources can be used in a compressed form.\ninclude_package_data -\u0026gt; when set to true you can specify patterns in a MANIFEST.in file at the root of your repo (or wherever setup.py is) to include non-Python files along with the package. By default Python packages only consist of the Python source code files so if you need other files for the package to correctly operate and create the MANIFEST.in. For example:\ninclude project\\spec.yaml include project/spec.yaml include project\\spec.schema.json include project/spec.schema.json recursive-include project/pdoc *.* recursive-include project\\pdoc *.* üëÄ If the file pattern didn\u0026rsquo;t match, the file will simply not be included. But because Windows and *NIX systems have a different path separator, you will likely need to duplicate the includes if you\u0026rsquo;re building the project on more than one platform.\npackages -\u0026gt; if you follow the standard package structure that I outlined, you will always use find: directive here. This is equivalent to calling find_packages() in setup.py and it makes setuptools discover the packages without having to list them explicitly.\npython_requires -\u0026gt; minimum required version of Python for the project to work.\ninstall_requires -\u0026gt; a list of pip packages that your package uses and depends on.\nconsole_scripts -\u0026gt; a list of commands that will automatically be exposed when pip installs your package. For example mkcommit = mkcommit.main:main maps an mkcommit command that you can run in the shell to the function main in the module mkcommit.main. This corresponds to executing your def main() from main.py that\u0026rsquo;s located in mkcommit folder in your repo. Take a look at mkcommit\u0026rsquo;s code if this sounds confusing and track it. You\u0026rsquo;ll realize it makes sense.\ndev -\u0026gt; these are tools that are necessary for the package only during development but not when a 3rd party wants to use your package. For example nox is used to automate package testing and deployment but the end user should never want to touch nox and the package itself works perfectly without it installed.\nflake8 section -\u0026gt; this is the configuration I use for my linter of choice, which is flake8. The linter is used to force yourself and other people to maintain good standardized code style.\nBuilding your package When you want to create a package and share it with others the easiest thing to do is:\npython -m setup bdist_wheel # or python -m build If you run it in the same directory where your setup.py lives, your package should be zipped into a *.whl file.\nüëÄ You can unzip *.whl files just as if they were normal *.zip folders.\nYou can now send the file to somebody and tell them to install it:\npip install \u0026lt;name\u0026gt;.whl That\u0026rsquo;s it. setuptools might make it a pain for developers but it makes things so much simpler for the users. After all, developers should manage complexity, not the end users.\nDeploying your package If you want to deploy your package to a registry, an internal company registry or pypi.org, you should use twine. For PyPi it\u0026rsquo;s quite simple:\npip install twine # install twine twine upload -r testpypi dist/* # test if the upload works twine upload dist/* # upload your package You can learn way more from the documentation.\n‚ö† Beware: a package once uploaded to PyPi can never be removed. All packages and their versions are immutable so make sure you don\u0026rsquo;t make mistakes here. If you exposed some credentials this way, change them immediately!\nFinal words So yeah, it might be a bit dense but with the minimal amount of information outlined in this article you should be able to hit the ground running with Python packages. I will leave you with a thought: I\u0026rsquo;ve seen large commercial projects set up as folders of scripts where stringing any two parts together was an incredibly painful mess. You shouldn\u0026rsquo;t wish the same happens to your project if you want it to enter production. The patterns that were set up so far were long years in development and involved a lot of discussions and compromises. There are newer, more convenient systems like Poetry but until they take the industry by storm, sticking to the standards is your best chance for success, particularly because most Python developers are already familiar with them, which makes working in teams and open-source communities nicer. If you want to use Poetry, fine, but don\u0026rsquo;t ignore its older brother. That\u0026rsquo;s simply not an option (yet).\n","permalink":"http://kjczarne.github.io/2022-01-17-seven-sins-of-python-sin-6/","summary":"Sin number 6: Packaging not done right Packaging Python projects properly can be truly a pain in the neck. However learning how to properly set up a package is extremely valuable because adherence to standards means more people can use your package efficiently.\nüëâ The biggest sin of all things package-related is storing Python projects as simple collections of directories.\nWhence the temptation? Python is a simple scripting lanugage so the natural tendency newcomers have is to simply create folders with a bunch of scripts and then run those folders one by one.","title":"Seven Sins of Python - Sin 6"},{"content":"A while ago I had a brainwave when reading about the Agile Software Development best practices. I\u0026rsquo;ve recently found this idea somewhere in my todo lists and decided to finally give it a try, especially given the fact that my new year\u0026rsquo;s resolutions never worked for me.\nüëâ The idea: forget new year\u0026rsquo;s resolutions, write user stories for your life instead.\nBefore I go in-depth on why I think you should write something akin to user stories for your life plans, since it\u0026rsquo;s barely the beginning of January 2022 let\u0026rsquo;s look at why new year\u0026rsquo;s resolutions are not the way to go (at least in my opinion).\nNew year\u0026rsquo;s resolutions The long-running tradition of new year\u0026rsquo;s resolutions is somewhat legendary for its ineffectiveness. I mean, really, how many people do you know that really did stick with their resolutions in the long run? I\u0026rsquo;ve had my fair share of these, e.g. cutting out most forms of sugar from my diet. It never works. And I have a few ideas why it doesn\u0026rsquo;t.\nThey\u0026rsquo;re too general These resolutions tend to be quite general in their form. How many times have you had resolutions like:\nI will spend more time with my family next year. I will finally open up a business next year. I will lose a few pounds next year. None of these statements provide a good motivation for why the resolution might be important and for whom. It also ignores the aspect of you playing different fiddle in many different bands. You might be both a mother and a surgeon. You might be both an airline pilot and a son to a cancer patient. Different roles you have to assume in various contexts require you to alter your behavior and your priorities.\nThey\u0026rsquo;re scoped for the duration of an entire year Notice that each of the examples I mentioned say about next year. None of those statements say when exactly is the resolution going to be fulfilled. In January you succumb to the illusion of having plenty of time so you just keep telling yourself: next week I will stop eating sweets, next week I will schedule a family get-together or after all it can be in 2 or 3 weeks, I\u0026rsquo;ve got plenty of time now.\nThis is the exact same problem each software developer must fight against every time a sprint starts. The conventionally short duration of a sprint means that a developer needs to aggressively prioritize, split up large tasks and schedule them in the now and avoid succumbing to the illusion that there\u0026rsquo;s plenty of time at the beginning of a sprint. Some teams go to extremes and enforce very short sprints, e.g. of 2-3 days but if you\u0026rsquo;re uncertain 1-2 weeks is usually a good middle-ground.\nüëÄ By coming up with a new year\u0026rsquo;s resolution for the duration of the entire year, you\u0026rsquo;re essentially creating a one-year sprint for yourself and you will usually end up wasting a lot of time when the sprint is too long.\nThey\u0026rsquo;re not really actionable Let\u0026rsquo;s take a closer look at the very clich√© I will go on a diet next year and lose weight. Sit and think for a moment what that statement says about the actionability of the process. How exactly are you going to accomplish losing weight? What will the diet entail? What will be the allowed amount of saturated fatty acids and sugars in your diet? Will you exercise? If so, how often and for how long?\nIf you really want to commit to change writing I will go on a diet next year and lose weight in huge red capital letters on the wall over your bed will be of little value if you don\u0026rsquo;t have an actionable plan. You have to determine what resources (time, money, effort, tools, etc.) you will need to succeed in accomplishing the entire goal but the goal is massive and you will quickly get confused without proper progress tracking and task planning.\nThe same happens in software. Rookie developers will often say I want to create an app that finds me the best boba tea deals in the area and jump head-first into the project, realizing 2 weeks later that the task is beyond their means because there are just so many things to take care of: will the front-end be prepared in a Web Framework like React.JS or vanilla HTML/CSS/JS, will the backend service be deployed on AWS or Azure, how should the service be monetized, where do you source the data, and so on and so forth\u0026hellip;\nüëÄ It is often more than okay to take way more time as long as you can accomplish something of value, something that just works but isn\u0026rsquo;t necessarily very pretty or easy to use. Same thing goes for the challenges in life. It\u0026rsquo;s often okay to take 2, 3, even 10 years to get into shape. But it\u0026rsquo;s not okay to slack off and put things off because the time you initially estimate for a large challenge will almost always be greater than you think. What you should do is split up huge tasks into tiny ones and put in the appropriate effort into planning and analysis. It\u0026rsquo;s better to spend time analyzing and planning than going a completely false route and then having to start from scratch.\nüëÄ Some authors like Grant Cardone in his The 10X Rule take this to extremes and claim you should aim for 10x more and expect that the resources you will need will almost always end up exceeding estimations. I found that while aiming for 10x more might make me less than motivated and more overwhelmed than anything, the part where the time and resources to achieve baseline results can often overrun to 5x or 10x the initial estimations in time and costs holds generally true if you have little data to perform bona fide calculations. These estimations get more on-point the more experience you gain in resource allocation and the more data you have available. Sadly, I cannot recommend Cardone\u0026rsquo;s book as it can be summarized with one sentence and I don\u0026rsquo;t want my friends to lose money and time.\nA word about Agile So at the very beginning of the article I\u0026rsquo;ve mentioned Agile and before we move on to the gist of the article I need to explain away a few things. My approach to Agile is the same as to any other tool: you should use it when you need it. Agile happens to be one of those tools that most software projects and most companies should prefer.\nüëÄ Agile Development in a short and overly simplistic summary could be described as introducing changes and new features into a software project at a very quick pace. Many summarize it as move fast and break things, others say it\u0026rsquo;s all about decreasing the time it takes for the actual user to see the product in its minimal form and empower the users to guide the prioritization of feature requests and bug fix requests.\nAs such, Agile is a great approach when one would expect high variablity of requests coming from the end customer or really any stakeholder.\nüëâ The rule would then be: unless your product\u0026rsquo;s stakeholders are not expected to change their mind frequently or unless you\u0026rsquo;re working following a strict immutable specification document, you should probably be using the Agile methodology.\nUser stories So Agile makes use of these so-called user-stories profusely to represent requirements that various stakeholders have for your project. They usually have a form that represents the role of the stakeholder, the request and the rationalization of such a request. A much loved and well tested template for a user story looks kind of like this:\nü§î As a \u0026hellip; I want \u0026hellip; because \u0026hellip;\nThat\u0026rsquo;s really it! Although the name story might imply something lengthy and winding, a user story should generally be expressed with a single sentence.\nThe art to user stories Writing good user stories and knowing how to handle them is crucial. The first few stories for a project should be fairly general and should describe the intended functionality for the project in question. It sounds simple enough but to me, the crucial part is always knowing how to split them up into smaller stories that are manageable within a sprint which is usually a one- to two-week period with a clear end goal. I always liked to have user stories split up in such a way that one story fits exactly with the time you have in a sprint. So if your sprint is 2 weeks, each person should take on exactly one user story and finish it before the time elapses.\nHow they address the problems of resolutions I\u0026rsquo;ve written that new year\u0026rsquo;s resolutions are:\ntoo general scoped for a time-frame that\u0026rsquo;s simply too long (entire year) not actionable If you master the writing of user stories you can basically solve those problems right away:\nuser stories are concrete -\u0026gt; they require you to put yourself or somebody else into the role of a stakeholder and they force you to rationalize your choices user stories can be split up where one story fits one sprint -\u0026gt; this forces you to think in terms of days not months or years user stories can be acted upon -\u0026gt; a well written story will outline exactly what needs to be done to accomplish a partial goal User stories for your life So what I am going to do now is outline the few general stories that I\u0026rsquo;ve written for myself for 2022 and I will describe how I am going to handle them in the coming months. A year later I will provide an update as to whether things worked out better than with new year\u0026rsquo;s resolutions (of which I haven\u0026rsquo;t succeeded in accomplishing even a single one).\nStep 1: writing down the top-level stories For privacy reasons the stories that I paste here will sound a bit general, feel free to make yours as concrete as possible. I place them here both to give you an example of what they might look like and for some degree of personal accountability.\nAs a son I want to spend more time with my mother because she needs all the help she can get to support the elderly family members that she takes care of. As a boyfriend I want to spend more time with my Significant Other because we both want a healthy stable future that we can plan together and I have to do my due dilligence. As a brother/cousin I want to help my siblings/cousins with their studies because their success in life increases the chances of a better and healthier life for our entire family. As a developer I want to learn advanced concepts in C++ programming from my shortlist so I can better support the development efforts for my employer. As a developer I want to create at least one high-performance concurrent application in Rust so that my understanding of parallel and concurrent computing improves to a point where it becomes effortless. As a prospective business owner I want to educate myself on the basics of accounting, German tax law, people management and resource management to successfully create and lead a small business that will sustain myself and my family in the future. As a sugar addict I will slowly phase out sweets and excessive fruit from my diet by reducing the consumption by 5-10% in mass every week because I want to enjoy a longer, better-quality life and excess carbohydrates exacerbate my familial risk of type 2 diabetes. As a person struggling with procrastination I will fully commit to the timeboxing technique, aggressive time tracking and task batching because I need to reduce context switching and maximize the amount of things I can get done to be able to accomplish at least 80% of what I originally intended. ‚ùó Pay attention to who the stakeholder for your story is. If the story involves other people consider asking them what they feel is important and what they would want. If you\u0026rsquo;re creating a tool for a user, the user needs to drive its development. If you\u0026rsquo;re creating a plan for spending time with your loved ones, ask them when, where and how they would want to spend time with you.\nStep 2: when in doubt, split it Many of the stories you\u0026rsquo;ll come up with will end up being not very actionable in the beginning. That\u0026rsquo;s when splitting them up might help. For example let\u0026rsquo;s take: As a son I want to spend more time with my mother because she needs all the help she can get to support the elderly family members that she takes care of. How exactly will I accomplish this? For context, I live in Germany while almost my entire family lives in Poland. I can split the story up fairly easily, I just drop the role part because it stays the same in case of each sub-story:\nI want to visit home at least once in two months or optimally once per month because it is not really possible for my family to visit me. I want to allocate more time for a phone call at least once in 3 days because the more often I speak to my mum, the better she will feel. I want to reduce the time of a single phone call because the longer we speak the less concrete the conversation gets and we lose time that could be allocated to other urgent tasks instead. The same procedure can be applied to nearly any story and in the end this generates a tree of tasks that you can easily put somewhere in your To-Do app, set deadlines for each and then work at it whenever you allocated time for it.\nStep 3: prioritize and measure progress Your time is sadly finite and you need to treat it like you treat savings. To allocate time intelligently, you need to know the priority of each of the stories. The easiest way is to sort them in order of increasing or decreasing priority.\nüëâ Remember: \\(important \\ne urgent\\). Use The Eisenhower Method to delegate urgent but unimportant tasks. You should at all times act upon whatever is urgent and important at the same time.\nFor me, the most important meta-story is As a person struggling with procrastination I will fully commit to the timeboxing technique, aggressive time tracking and task batching because I need to reduce context switching and maximize the amount of things I can get done to be able to accomplish at least 80% of what I originally intended. It basically says that I want to accomplish at least 80% of these challenges I\u0026rsquo;ve set up. That means that out of 8 stories that I\u0026rsquo;ve presented I should finish 6.5. So I should be pretty satisfied next year if out of those 8 stories, 6 have succeeded.\nüëÄ You cannot evaluate what you can\u0026rsquo;t measure. Even if your measure of success is arbitrary (like mine), it\u0026rsquo;s better than having no ways to measure your success at all.\nBecause I might end up moving accross the ocean later in 2022, my further priorities are spending time with my girlfriend and my family and helping out my siblings in setting themselves up for a success in the future. It will hurt less if I don\u0026rsquo;t manage to start a company before leaving Germany because I know that this could still be done upon my return, while interpersonal relationships often cannot be repaired.\nüëâ In your prioritization practices, I would recommend not to blindly dive into more work but to make sure that your loved ones are not left out. While it might not feel productive, it\u0026rsquo;s extremely important for everybody\u0026rsquo;s mental health to take good care of your interpersonal relationships. Humans are animals that require other humans to function well.\nStep 4: schedule When you have your tree of stories in hand and the associated tasks naturally written out, you can proceed to scheduling. It\u0026rsquo;s best to allocate a day or two, sit down with a cup of good coffee and make a good long-term plan that allocates each individual bite-size sub-story or sub-sub-story or even sub-sub-sub-story to a sliver of your time in the year. Make sure you keep the accountability time-frames short, i.e. try to not spend more than 2 weeks on a single task. If that\u0026rsquo;s the case, it should probably be split up into even smaller sub-tasks.\nThis is common practice in many strains of Agile. A story should fit into a sprint and you should have something to show at the end of it.\nStep 5: maintain discipline Probably the hardest part is actually keeping it up and staying motivated. For that, sadly, I still don\u0026rsquo;t have a silver bullet. I recognize that each and every one of us will occasionally suffer periods of feeling low or downright anguish that disables one from conquering challenges altogether. My way of staying motivated is the thought of my own death and what will be left behind. I want to depart life knowing that I did as much as possible to make the lives of other people better and established some form of legacy that is tangibly useful to others. These things originally drove me towards a career in software development and are now pushing me in the direction of a degree in engineering as well as towards spending more time with the people I love. I am somewhat at peace, knowing that I will never really be able to strike a balance between the two, there is just no simple way of finding an optimum. But the thought of how I want to be remembered when I\u0026rsquo;m gone makes me strive towards trying things, making things and making things work.\nI think everyone should attempt to find a motivating factor behind each thing one wants to accomplish. That\u0026rsquo;s why the because part of the user stories is so important in my opinion. It outlines the motivation behind the story and if the motivation simply isn\u0026rsquo;t strong enough you will end up not following through.\nOther ways that you may try to stay motivated:\nfind an accountability partner -\u0026gt; find someone to whom you will report your progress as if you were talking to a manager, make sure this is a person that knows you well and knows when to push you and when to have mercy over you use a tool like Habitica -\u0026gt; if you like games, you might find that forming new habits or fulfilling tasks as if it were a game might be helpful; I used Habitica for a while before switching to a simple To-Do + Calendar system give yourself a financial penalty when you don\u0026rsquo;t accomplish an important task -\u0026gt; services like Beeminder can charge you real dollars if you don\u0026rsquo;t fulfill your goals; I haven\u0026rsquo;t tried it personally but I think it\u0026rsquo;s a cool concept for people who like to constantly have an axe hanging over their necks. Step 6: be Agile Quicker iteration on particular tasks will give you more and more ideas as to where you want to take yourself and your loved ones as the time progresses.\nüëâ This means you should never treat stories as something set in stone and you should make them react to change.\nWhen a massive opportunity comes your way sometime in 2022 and it completely changes your plans, take a few minutes and revise the plan, alter the stories accordingly and work to the new plan. After all, this is the core philosophy of Agile.\n‚ùó But should you allow yourself to give up on an important goal just because you feel like slacking off or just because you\u0026rsquo;re scared? Address your lack of energy, address your fear, don\u0026rsquo;t be scared to leverage therapy if you need to, but above all make sure you don\u0026rsquo;t just ignore your goals. Change them and tweak them, throw them out if you really need to or have no time, but be self-aware and try to always acheive your top priorities at a reasonable cost. Health should be always your top priority, because when your mind and body are broken, nothing else can be accomplished.\nFinal words So, now you have an idea of what I think is vastly better than new year\u0026rsquo;s resolutions. I hope you\u0026rsquo;ll hop along for a ride with me and see for yourself how many more things you were able to get done after committing to this approach.\nI wish you all the best in 2022, may all your stories come to fruition and make sure to subscribe to the newsletter to get a follow-up to this article in 2023.\n","permalink":"http://kjczarne.github.io/2022-01-05-forget-new-years-resolutions-do-this-instead/","summary":"A while ago I had a brainwave when reading about the Agile Software Development best practices. I\u0026rsquo;ve recently found this idea somewhere in my todo lists and decided to finally give it a try, especially given the fact that my new year\u0026rsquo;s resolutions never worked for me.\nüëâ The idea: forget new year\u0026rsquo;s resolutions, write user stories for your life instead.\nBefore I go in-depth on why I think you should write something akin to user stories for your life plans, since it\u0026rsquo;s barely the beginning of January 2022 let\u0026rsquo;s look at why new year\u0026rsquo;s resolutions are not the way to go (at least in my opinion).","title":"Forget New Year's Resolutions, do this instead"},{"content":"Sin number 5: global destruction Every time I am asked about global keyword in Python, I get a split-second heart attack. Personally I think it is one of the most unnecessary and dangerous keywords that Python has to offer. I will go one step further and postulate that if you\u0026rsquo;re using nonlocal you\u0026rsquo;re probably doing it wrong.\nüëâ The essence of this problem is misunderstanding the purpose or the mechanics of scope in Python.\nWhence the temptation? Consider a very simple example. Imagine you\u0026rsquo;ve just learned about the existence of functions in Python and you want to reuse repetitive pieces of code as much as possible:\ndef concatenate_all_strings(): string1 = \u0026#34;a\u0026#34; string2 = \u0026#34;b\u0026#34; string3 = \u0026#34;c\u0026#34; return string1 + string2 + string3 print(concatenate_all_strings()) Great! This works. But what if you want to use string1 somewhere else? Let\u0026rsquo;s say I type up 100 more lines of code and I\u0026rsquo;m suddenly in need of printing out the string1 variable:\ndef concatenate_all_strings(): string1 = \u0026#34;a\u0026#34; string2 = \u0026#34;b\u0026#34; string3 = \u0026#34;c\u0026#34; return string1 + string2 + string3 print(concatenate_all_strings()) # 100 more lines of some code... print(string1) What you get when you run this script would be: NameError: name 'string1' is not defined. Now you start searching the Internet for a solution to your problem and inadvertently you find that the simplest way to make a variable that exists within a function body accessible elsewhere is to use global. You will then merrily refactor the above to:\ndef concatenate_all_strings(): global string1 global string2 global string3 string1 = \u0026#34;a\u0026#34; string2 = \u0026#34;b\u0026#34; string3 = \u0026#34;c\u0026#34; return string1 + string2 + string3 print(concatenate_all_strings()) # 100 more lines of some code... print(string1) Why is this a sin? This creates a potential for name conflicts and introduces a lack of clarity. When you refuse to use scoped variables and declare everything as global when you want to share variables, you will inadvertetly run into situations where a local variable has the same name as one in an outer scope and depending on which one is evaluated when, you will either end up with the value declared in the outer scope or the inner scope. Furthermore, any implicit modification of the global state makes code harder to understand because you end up searching for the variables in each function body.\nThis is especially painful when you realize how easy it is to avoid using global altogether and that avoiding global comes naturally when you know some proper functional patterns.\nHow to recognize a sinner? Any use of global or nonlocal should put up red flags. Honestly, I haven\u0026rsquo;t seen any piece of code in my life that couldn\u0026rsquo;t be refactored to avoid these keywords and such refactoring always resulted in improvements in code maintainability.\nüëÄ Remember, just because some solution is more concise and quicker to implement, doesn\u0026rsquo;t mean that it will lead to better maintainability. Always assume that somebody else will read your code, thus you should use patterns that make it easy to pinpoint the flow of information in a clear way. global is not one of those patterns. Also, consider that even if nobody else will end up reading your code in the future, your future self might not remember what the project was about in a few weeks. So if not for the sake of your colleagues, avoid antipatterns as a good deed for your future self.\nHow to repent? Understand and leverage scope Most uses of global stem from the misunderstanding of scope. Scope essentially means that whatever is within a function or a class belongs to that function or class if it\u0026rsquo;s declared there. Anything from the outer scope is accessible to the inner scope but the inverse is not true. You should put variable declarations into such a scope that can be accessed by all the consumers of those variables. In our example this would be the top-level scope of the Python module that we were running:\nstring1 = \u0026#34;a\u0026#34; # accessible to both `concatenate_all_strings` and top-level `print` def concatenate_all_strings(): string2 = \u0026#34;b\u0026#34; # accessible only within this function string3 = \u0026#34;c\u0026#34; # accessible only within this function return string1 + string2 + string3 print(concatenate_all_strings()) # 100 more lines of some code... print(string1) The good part is that if I needed to declare a variable named string2 in the top-level of the script and print it but I would like to keep the original string2 value within the function I could simply do this:\nstring1 = \u0026#34;a\u0026#34; string2 = \u0026#34;lol\u0026#34; def concatenate_all_strings(): string2 = \u0026#34;b\u0026#34; # accessible only within this function string3 = \u0026#34;c\u0026#34; # accessible only within this function return string1 + string2 + string3 print(concatenate_all_strings()) # prints \u0026#34;abc\u0026#34; # 100 more lines of some code... print(string1) # prints \u0026#34;a\u0026#34; print(string2) # prints \u0026#34;lol\u0026#34; With scoping it\u0026rsquo;s clear where a particular variable belongs. Every time you enter function scope or class scope it\u0026rsquo;s a bit like entering a different room in a house. The mirror that hangs on the wall of your own bedroom looks different to the one in your bathroom. The name is still the same but the value doesn\u0026rsquo;t have to be and it still makes sense that two rooms have a mirror object within them.\nTreat functions like physical factory machines If you\u0026rsquo;ve worked with Python for a while you will realize that the solution above is kind of lousy and lazy as well. And if you paid attention in math classes you will realize that our function concatenate_all_strings does not really behave like a mathematical function.\nüëÄ In mathematics, a function is an instrument that takes a set of arguments and produces one value from that set of arguments. In programming, we call functions equivalent to mathematical functions pure functions.\nWhenever you have the chance you should parameterize what you can and use pure functions. In Python, if you combine that with type hints, the function signature, i.e. the function name alongside its parameters and return type, gives you a very clear idea of what the function does and how it should behave.\nstring1 = \u0026#34;a\u0026#34; string2 = \u0026#34;b\u0026#34; string3 = \u0026#34;c\u0026#34; def concatenate_all_strings(string1: str, string2: str, string3: str) -\u0026gt; str: return string1 + string2 + string3 print(concatenate_all_strings(string1=string1, string2=string2, string3=string3)) # 100 more lines of some code... print(string1) Notice how def concatenate_all_strings(string1: str, string2: str, string3: str) -\u0026gt; str tells you almost everything you need to know about the function. It takes in 3 strings and returns a single string and if the name is to be trusted it will probably concatenate the input strings. This function is pure. It does not modify the input in any way, it simply takes the input and produces some output, like a factory machine that takes in some raw material and returns a product. Actually, it\u0026rsquo;s even better because it does not destroy string1, string2 and string3 in the process so these can be later reused.\nIdentify repetition and parameterize Finally, the way I would refactor the example:\nfrom typing import List string1 = \u0026#34;a\u0026#34; string2 = \u0026#34;b\u0026#34; string3 = \u0026#34;c\u0026#34; def concatenate_all_strings(string_list: List[str]) -\u0026gt; str: result = \u0026#34;\u0026#34; for s in string_list: result += s return result print(concatenate_all_strings([string1, string2, string3])) # 100 more lines of some code... print(string1) When parameterizing functions that used to abuse global or nonlocal you will realize that there may be some sensless repetition involved and the number of parameters quickly explodes. What if I wanted to concatenate not 3 but 4, 5, 6, etc. strings? Every time I would like to add another one, I\u0026rsquo;d need to add it to the parameter list and then call the function with an additional argument. This is tedious. When you realize this is the way it\u0026rsquo;s going, think about generalizing the parameter set a bit more. In this case a list of arbitrary length might be the best choice. In other cases you might want to use generators, dictionaries, etc.\nü§î You might be wondering why I didn\u0026rsquo;t use the *args idiom and used a list as a parameter. Type annotations on *args and **kwargs can sometimes get tricky and this makes the function signature almost always less explicit. Some programming languages do not even support variable number of arguments in functions, Rust for example allows you to do that only in macros, which are essentially generating Rust code before compilation happens and are not functions that will be evaluated at runtime. My advice is to avoid *args and **kwargs unless there is a very good reason for the user interface to leverage them.\nLearn advanced scope patterns Last, let\u0026rsquo;s take a look at something more advanced if you\u0026rsquo;re coming here for some more serious patterns.\nScoping can be really powerful. My favorite example is a closure. In Rust closures are basically lambda functions that can capture their outer scope:\nfn do_something() { let x: i32 = 5; let add_x = |i| i + x; // `x` is grabbed from the outer scope add_x // `add_x` is returned } let lazy_add_x = do_something(); let result = lazy_add_x(5); println!(\u0026#34;{}\u0026#34;, result); In Python, all functions can capture their outer scope. Thus the idea of a closure should usually be expressed with a nested function:\nfrom typing import Callable def add_x(i: int) -\u0026gt; Callable[[], int]: x = 5 def wrapper(): # `x` is grabbed from outer scope return i + x return wrapper lazy_add_x = add_x(5) result = lazy_add_x() print(result) print(x) # fails, `x` only exists within `add_x` scope Conclusions üëâ Never use global and nonlocal. If you find you need it, it\u0026rsquo;s probably because you have a design flaw in your code or you\u0026rsquo;re misunderstanding scope.\nüëâ When using functions parameterize what you can for better code reuse.\nüëâ Use pure functions whenever you can. Don\u0026rsquo;t silently modify state, return values instead.\nüëâ If you find yourself copy-pasting or repeating more or less the same thing over and over again, there\u0026rsquo;s probably a more general parameter set that you could leverage.\n","permalink":"http://kjczarne.github.io/2021-12-28-seven-sins-of-python-sin-5/","summary":"Sin number 5: global destruction Every time I am asked about global keyword in Python, I get a split-second heart attack. Personally I think it is one of the most unnecessary and dangerous keywords that Python has to offer. I will go one step further and postulate that if you\u0026rsquo;re using nonlocal you\u0026rsquo;re probably doing it wrong.\nüëâ The essence of this problem is misunderstanding the purpose or the mechanics of scope in Python.","title":"Seven Sins of Python - Sin 5"},{"content":"Sin number 4: Exception frenzy Python\u0026rsquo;s Exception class is probably one of the most abused and misused features of the language. It\u0026rsquo;s also something that no developer can escape from.\nWhence the temptation? An Exception is a pretty natural element of any language. In all languages one will always have some need for a runtime error. In case of Python, most runtime errors inherit from the Exception class. Though technically not a base class (for that would be BaseException), it should be treated like a base class and it often isn\u0026rsquo;t.\nOne of the most common forms of antipatterns with exceptions in Python are:\ncatching exceptions instead of checking values using Exception class for user-defined exceptions directly abusing try/except clause Why is this a sin? Proper patterns enforced when using exceptions mean that your code is more stable and more readable at the same time. Novice developers will often abuse try/except and raise just because it\u0026rsquo;s easy to catch something wrong or cause something wrong to happen.\nHow to recognize a sinner? This is by far the most common antipattern I\u0026rsquo;ve seen, which almost always appears when working with dictionaries:\ntry: print(some_dict[\u0026#34;sth\u0026#34;]) except Exception: pass There are two problems with this solution. First, what\u0026rsquo;s caught is a general Exception class. This means that if we place any other code into the try block that throws any other type of exception, we will not be able to detect the problem:\ntry: print(some_dict[\u0026#34;sth\u0026#34;]) int(\u0026#34;I cannot be converted to an integer\u0026#34;) except Exception: pass The code above will run without any issues reported! To fix this we could hone in on the concrete type of an exception that the invalid key access throws for a dictionary:\ntry: print(some_dict[\u0026#34;sth\u0026#34;]) int(\u0026#34;I cannot be converted to an integer\u0026#34;) except KeyError: pass Now, we\u0026rsquo;re catching only the KeyErrors. That\u0026rsquo;s good because this means that our ridiculous int cast in the example above will crash the application and we\u0026rsquo;ll be forced to fix the issue. I guess you can now see how dangerous operating try/except can be.\nExceptions can be too general This also explains why we should create subclasses from Exception instead of raising Exception itself everywhere in our program. Most exceptions are not equivalent and it will be easier for the consumers of your Python package to handle failure cases. So doing this would be fairly bad:\nx = 0 if type(x) is not int: raise Exception(\u0026#34;x should be int\u0026#34;) if x \u0026gt; 0: raise Exception(\u0026#34;x should not be greater than 0\u0026#34;) How to repent? So let\u0026rsquo;s fix the issues that we\u0026rsquo;ve outlined in the previous section. We\u0026rsquo;ve already covered catching KeyError but frankly if you are able to avoid try/except, do it. In case of dictionary key access, it\u0026rsquo;s pretty easy:\nif \u0026#34;sth\u0026#34; in some_dict.keys(): print(some_dict[\u0026#34;sth\u0026#34;]) else: print(\u0026#34;No sth key in dict\u0026#34;) I like to call this pattern: check for values instead of catching errors. You should always try to cover all possibilities when working with something that might fail. Languages with strong functional paradigms like Rust will usually enforce this with structural pattern matching. Python 3.10 has introduced pattern matching, so if you\u0026rsquo;re a fan of functional, you could express the same like this:\nmatch some_dict: case {\u0026#34;sth\u0026#34;: x}: print(x) case _: print(\u0026#34;No sth key in dict\u0026#34;) I find pattern matching an absolutely brilliant option. Notice that in the example above I didn\u0026rsquo;t have to use .keys() and in at any point, I just told the interpreter to pattern-match a sub-dict of the some_dict and place the value into a variable named x.\nProbably the cleanest solution is to use collections.defaultdict:\nfrom collections import defaultdict some_defaultdict = defaultdict(lambda: None, some_dict) print(some_dict[\u0026#34;sth\u0026#34;] or \u0026#34;No key sth in dict\u0026#34;) defaultdict behaves just like a normal dictionary but when it\u0026rsquo;s created you give it a function that will make a default value when a particular key is missing. I usually like to use it with lambda: None so that subsequently I can use the something or default idiom.\nüëâ Avoid try/except when you can unless you really have to handle an error and there is no way to check for a value without resorting to error handling.\nMaking exceptions more precise So going one step further if you\u0026rsquo;re creating your own exception cases you should also make subclasses from the Exception class for each family of errors. The example that we used before in the previous section to demonstrate this should ideally be refactored as:\nx = 0 if type(x) is not int: raise TypeError(\u0026#34;x should be int\u0026#34;) if x \u0026gt; 0: raise ValueError(\u0026#34;x should not be greater than 0\u0026#34;) TypeError and ValueError are already built-in error classes in Python which are a great option for generic errors when a wrong value or an improper type has been provided. But consider the following example:\nif obj_a == obj_b: raise Exception(\u0026#34;Objects should not be identical\u0026#34;) This one doesn\u0026rsquo;t really fit with ValueError or TypeError since it\u0026rsquo;s more about equality of two custom objects (assumming obj_a and obj_b exist). Instead we should define a custom Exception type and raise it:\nclass ObjectsIdenticalException(Exception): \u0026#34;\u0026#34;\u0026#34;Raised when two objects are identical\u0026#34;\u0026#34;\u0026#34; pass if obj_a == obj_b: raise ObjectsIdenticalException(\u0026#34;Objects should not be identical\u0026#34;) This way any consumer of your package can decide to catch ObjectsIdenticalException just as we have caught KeyError for the dictionary keys instead of catching the most general Exception.\n","permalink":"http://kjczarne.github.io/2021-12-27-seven-sins-of-python-sin-4/","summary":"Sin number 4: Exception frenzy Python\u0026rsquo;s Exception class is probably one of the most abused and misused features of the language. It\u0026rsquo;s also something that no developer can escape from.\nWhence the temptation? An Exception is a pretty natural element of any language. In all languages one will always have some need for a runtime error. In case of Python, most runtime errors inherit from the Exception class. Though technically not a base class (for that would be BaseException), it should be treated like a base class and it often isn\u0026rsquo;t.","title":"Seven Sins of Python - Sin 4"},{"content":"C++ is a great language. As much as I hate it I cannot ignore how important it is and how much it brought to the table in it\u0026rsquo;s 36 years of existence. I have tremendous respect for Bjarne Stroustrup for creating the so-called C with classes and I personally think that it\u0026rsquo;s one of the best things that happened in programming language designs around the time when it came to existence.\nBut C++ is a language that we might slowly see becoming legacy technology. Here\u0026rsquo;s my take on the whole C++ shebang.\nüëÄ For context: I started my career as a software developer with JavaScript and Python and then worked with C# for a good few months. I haven\u0026rsquo;t touched C++ until a few months ago simply because I never had a need to. But there are situations in which you will need a much faster language that compiles to native code instead of something that always incurs a massive interpreter overhead. For the past two months I\u0026rsquo;ve been learning C++ with the support of expert developers at work. My view may be a bit simplistic and I\u0026rsquo;d enjoy to start a discussion and hear other views. I made sure it\u0026rsquo;s not my resistance to change that makes me dislike C++ but this article naturally deals with some speculations about the future which we cannot know for certain, hence if you see that I\u0026rsquo;ve overlooked something, don\u0026rsquo;t hesitate to point it out.\nüëâ In the examples below I will be using C++17 because that\u0026rsquo;s what I\u0026rsquo;m using at work. Keep in mind that some of the examples that I describe, e.g. template constraints have been added with the C++20 standard. Why aren\u0026rsquo;t we using C++20? Well, using the latest standard is one of the problems I listed, so read on to learn more.\nThe problems with C++ So, let\u0026rsquo;s start with the reasons that I dislike C++. I like to call them genuine problems.\nC++ is extremely verbose Creating production-level code in C++ ofter requires a lot of boilerplate. This is bad because large codebases usually incur higher maintenance costs. On top of that, the syntax of the language doesn\u0026rsquo;t make things better. Take for example the following template declaration which roughly corresponds to a very liberal generic type:\ntemplate \u0026lt;typename T\u0026gt; void do_something(T i) { if constexpr (std::is_integral\u0026lt;uint8_t\u0026gt;(array)) { // ... } else { // ... } } Compare that to a generic function in Rust:\nfn do_something\u0026lt;T: u8\u0026gt;(i: T) -\u0026gt; () { // ... } This relative verbosity is prevalent in nearly all constructs. You quickly get sick of std::string make_string_repr(std::shared_ptr\u0026lt;MyClass\u0026gt;, std::string str_template) and you promptly swivel your display from vertical orientation back to landscape (happened to me). In general C++ tends to be way more verbose than languages like Python, though you can learn to make things more concise over time. An expert friend of mine at work once refactored a function I\u0026rsquo;ve created from 70 lines down to about 10. And this is a nice seguey into our next talking point\u0026hellip;\nIt takes years to get proficient in C++ The complexity of the language entails this naturally - you cannot become a good junior developer within a few months. Well, at least if you\u0026rsquo;re average like me, you will make a lot of mistakes especially at the very beginning of your journey. It is an immensely complex language especially for beginners or people comming from higher-level interpreted languages.\nMemory safety is not guaranteed Another issue/feature of C++ is the fact that the developer has to think about memory management very consciously all the time. For example, the following code compiles:\nvoid do_something() { int some_int; // a lot of code ... int* unknown_int_ptr; // a lot of code ... int* some_int_ptr = \u0026amp;some_int; } Imagine that between the declaration of the integer and the declaration of the pointer you placed a lot of code and nowhere have you actually assigned a value to the some_int variable. This generally results in so-called undefined behavior, which is basically compiler-dependent and not guaranteed by the standard. So some_int_ptr when dereferenced will point to some_int but we cannot make any guarantees about its value, because it won\u0026rsquo;t make any sense anyway. And this statement is legal in C++ as it is in C.\nNow to the unknown_int_ptr. Notice that it has no address assigned so it essentially is a pointer into nothingness. Again this code compiles. Some smarter compilers might point out that this might be a bug but that depends on the way you\u0026rsquo;ve set up your build toolchain. If you dereference unknown_int_ptr you will actually attempt dereferencing a nullptr which is also undefined behavior and in some cases pretty hard to catch!\nIn Rust, this is explicitly disallowed when using references:\nfn do_something() { let some_int: u8; // won\u0026#39;t compile! let unknown_int_ptr: \u0026amp;u8; // won\u0026#39;t compile! let some_int_ptr: \u0026amp;u8 = \u0026amp;some_int; // won\u0026#39;t compile! } üëÄ The reason why C and C++ do allow such silly operations is to give the developers maximum flexibility with their code. As such, it is the sole responsibility of the developer not to make such mistakes. (Un)fortunately developers are born to make mistakes. Rust takes a middle ground. It is still possible to do unsafe operations in Rust, albeit they need to be explicitly marked (placed in an unsafe { } block).\nüëÄ Some of the pointer management problems can be averted by using the so-called smart pointers which have been added in C++17. You can even emulate Rust\u0026rsquo;s ownership move logic with std::unique_ptr\u0026lt;T\u0026gt; template. If you\u0026rsquo;re unsure what this all means just disregard this block.\nUsing the latest standard might be risky I didn\u0026rsquo;t experience this personally but I\u0026rsquo;ve heard of a commercial project (of which details I cannot disclose) that was implemented in C++17 back when C++17 was a freshly released standard. Long story short, the MSVC Compiler had a bug that caused the developers a lot of headaches before they were able to realize that their code is ok but the compiler is not. You would think that such things are unacceptable but bugs happen in every compiler or interpreter out there. The problem is -\u0026gt; when you\u0026rsquo;re working with a complex language like C++ it\u0026rsquo;s inherently more likely that someone at some point will make a mistake. And that means you have to put lower trust into something as important as the compiler for the language.\nFiguring out build systems is ridiculously complicated My first look at the CMake-based build system generator toolchain in a large commercial project almost made me want to sign up for a 3 month break from work at a mental asylum. Now listen\u0026hellip;\nIn Python we usually need one or more setup.cfg files with a corresponding setup.py that loads it, finds the package files and the package is ready to be installed. Python uses the pip package manager for this, Node.JS has npm or yarn package managers, Rust has its absolutely phenomenal cargo package manager.\nü§¶‚Äç‚ôÇÔ∏è C++ does not have any good package manager whatsoever.\nThe closest we have to a package manager in C++ is the Conan package manager. So let\u0026rsquo;s say I want to depend on a few packages in my C++ project. What do I do? I need to nearly write my own build system using CMake and use Conan CMake files to even be able to talk to the package manager when invoking cmake. CMake actually generates Makefile on Linux or Visual Studio Solution files on Windows. Well, not always, depends on how you configure it. Because you could replace Makefile-consuming make with ninja which can also be used as an alternative to MSBuild on Windows, MSBuild being the tool normally responsible for building Solution (*.sln) files. Then you have to remember that cached Conan packages can sometimes interfere with fresh builds if certain configuration options like the version of the compiler has changed in between builds, so does the CMake target directory with its CMakeCacher.txt\u0026hellip; üò£\nThere\u0026rsquo;s a beautiful German adjective that describes this situation perfectly: bescheuert.\nüëâ In Rust to obtain packages necessary for a new project, all you need to do is add them to the list of dependencies in Cargo.toml and trigger a new project build. That\u0026rsquo;s it. That\u0026rsquo;s what dependency management should look like.\nCompiler error messages can be next to useless Last but not least, if you\u0026rsquo;ve ever compiled C++ code in your life you will know what I mean. The output produced by the compiler (especially MSVC) is usually quite uninformative and it often leads you on a wild goose chase. It happened to me lately that when using fmt I wasn\u0026rsquo;t able to find an improper usage of a formatter function because the line number info was hidden somewhere in the middle of an outlandishly long stack trace and my eyes just kept on slipping through it. It\u0026rsquo;s often very hard to debug weird compilation errors particularly where macros and templates are used.\nUltimately, why so many problems C++ has so many issues because it\u0026rsquo;s fairly old! Each new standard piled dubious features on top of the existing stuff with regards for maximum backwards-compatibility. Since a path has been taken with many language design choices, it is not really possible to now backtrack on certain decisions. Issues are being fixed and developer experience is being improved, albeit at a much slower pace than for most modern languages.\nWhy I think C++ is heading for the Elysian Fields You might have noticed that all examples I\u0026rsquo;ve provided for the bad stuff in C++, I\u0026rsquo;ve countered with examples in Rust. So, here\u0026rsquo;s my theory:\nüëâ I think Rust will replace C++ as the main systems development low(er)-level language within the next 20 years.\nIf the pace of adoption of Rust Programming Language keeps up, we might see Rust being the language that solves some of the issues that C and C++ faced since their conception. Rust is very promising because of:\nAn awesome toolchain with the cargo package manager with out-of-the-box documentation builder, unit test runner, childishly simple dependency management, etc. Full memory safety (unless explicitly turned off when you need to). Default immutability -\u0026gt; variables are immutable by default, this way you will e.g. never forget to lock a resource in a thread before using it if it\u0026rsquo;s mutable. Clear, concise syntax -\u0026gt; the syntax is clear, easy to read and above all - concise. Very informative, precise compiler errors and warnings -\u0026gt; many times the compiler suggested an actual solution to the issue I was facing. Speed. It tends to be even faster than C++ in many situations. Okay but just because I like Rust so much doesn\u0026rsquo;t mean everybody\u0026rsquo;s going to use it. So what indicators do we have at the moment that point to Rust slowly taking the market away from C++? Let\u0026rsquo;s look:\nRust is now the second officially supported Linux kernel language. Amazon started sponsoring Rust in 2019 under their AWS brand, for example Amazon\u0026rsquo;s Firecracker micro-VM project is implemented in Rust. Microsoft is rewriting some of their projects into Rust. 5th most-wanted programming language of 2020. Named most loved programming language of 2020. These are all big deals. Linux is the most used operating system in network servers, AWS the most popular cloud provider in the world, Microsoft owns a huge part of the operating system market as well as a good chunk of cloud computing market with its Azure platform. Hence these are all signals that if the pace is kept up, Rust might very well become a go-to for large-scale projects.\nDoes it pay off to learn C++ then? BIG FAT YES. Well, that\u0026rsquo;s a surprise. I go on bashing the language for the entire length of this article and then I drop that bombshell\u0026hellip;\nHere\u0026rsquo;s the harsh inconvenient truth for people who dislike C++: the number of projects implemented in C and C++ to date and the sheer popularity of the language make it impossible to ignore if you want to do low(er)-level development professionally. If you\u0026rsquo;re a freelancer or a startup owner you might enforce Rust, sure, however most companies will still like to leverage troves of C++ talent that is available currently on the market instead of trying to source Rust developers which are still few and far between, albeit growing in numbers by the day.\nAll in all, C++ projects tend to create so much technical debt and tend to be so voluminous that it will take years before Rust can make a massive break. But I sincerely believe that it is the first language on the market that has what it takes to start replacing good old C++ or at least challenge its throne rights.\n","permalink":"http://kjczarne.github.io/2021-12-21-c-is-the-new-cobol/","summary":"C++ is a great language. As much as I hate it I cannot ignore how important it is and how much it brought to the table in it\u0026rsquo;s 36 years of existence. I have tremendous respect for Bjarne Stroustrup for creating the so-called C with classes and I personally think that it\u0026rsquo;s one of the best things that happened in programming language designs around the time when it came to existence.","title":"C++ is the new COBOL"},{"content":"If were to read only one post from this blog and ignore all the others, here is a piece of advice that I would like to give to everyone who wants to vastly improve their career.\nüëâ The most priceless thing that will help you excel in anything you do is your brain. The second most priceless thing is your second brain.\nWhat I mean by that?\nIf you are able to build a robust reference system with a very short lookup time for any possible piece of information, you will excel at everything you do. The point of being great at your job is not being able to cram everything into your brain and recite formulas or code snippets from memory. If you\u0026rsquo;re able to do this, congratulations you absolutely beautiful savant human being - reach out in comments and please teach me how can I become more like you. If you\u0026rsquo;re average like me, having your little personal Wikipedia would probably help, wouldn\u0026rsquo;t it?\nI\u0026rsquo;ve found that Pareto principle definitely applies here and although people out there have created tons of contents about evergreen notes, personal knowledgebases, zettelkasten and second brains, you should start with something simple that has the potential to scale in the future but also be prepared to move your notes elsewhere if your initial choice proves stale for you. Finding the right system for you is always your responsibility and involves you experimenting with different tools before you decide to commit.\nWhat I use I use Obsidian because:\nCtrl+O brings up a quick-switcher where I can right away see last 10 notes I\u0026rsquo;ve recently opened. Ctrl+P brings up a command pallete that lets me quickly e.g. change from light mode to dark mode when the sun sets. It stores your files as plain Markdown files and you own all your data. You can sync it with their sync service, iCloud Drive, Google Drive, NextCloud, etc. They have a phenomenal iOS application. They have an open plugin system where anybody can develop a community plugin uses elements of the application. I can link and backlink my notes. I can view my notes in a graph view, which lets me discover unexpected connections between concepts. I can create Mermaid.JS graphs directly within the Markdown files, they just rended automatically. In essence Obsidian gives me:\nSpeed -\u0026gt; switching between notes is a matter of split-seconds, search is blazingly fast, I never have to search for commands in ridiculous menus like in OneNote Portability -\u0026gt; not only can I view my notes pretty much on any device but I can also process each note as a plaintext file which means that if I need any automation, it\u0026rsquo;s a matter of writing a basic Python script perhaps using the mistune Markdown parser. Extensibility -\u0026gt; the plugin system means that I can make the experience as complex or as simple as I need. I use among others: Quick switcher plugin Command pallette plugin Templates plugin Slides plugin Graph plugin Spaced repetition plugin Privacy -\u0026gt; I get to decide where I store my notes and how I split them up into different vaults. New learning opportunities -\u0026gt; the Spaced Repetition plugin in Obsidian is phenomenal for learning languages with way less useless complexity that comes with Anki flashcards. How to take notes There are just a handful of rules that I use to make this content aggregation effective:\nWrite big summaries on general topics -\u0026gt; I like to keep e.g. notes on syntax basics for programming languages in a single note that has headings organized into a hierarchy:\nWrite very small, atomic notes on narrower topics -\u0026gt; for example, an article about C++ pointers gets its own page. Whatever feels like a conceptually distinct thing, lands in a different, shorter, more digestible note. Those smaller notes can be then linked together:\nLink between notes aggressively but be smart -\u0026gt; you should use [[wikilinks]] as much as possible but be smart about it. Obsidian finds unlinked mentions of a particular note which lets you scour through mentions that haven\u0026rsquo;t yet been linked. Decide consciously which of these mentions deserve a link:\nTreat it like a garden -\u0026gt; your notes should predominantly serve you in the first place. But treating them like ancient scrolls in an old library will not bring you much value. Revise your notes frequently, iterate on different versions, weed out outdated and useless things from your knowledgebase, add and remove content as you see fit. The more you interact with your notes the more value you\u0026rsquo;ll be able to extract out of them. And they will be alive for longer.\nüëÄ If version control is something you\u0026rsquo;re looking for, my suggestion is to learn Git and look nowhere else. I personally do not use any version control system for my knowledgebase. That\u0026rsquo;s because I only care about the state of my knowledge at a single point in time, which is now. I treat my notes not as an end product that needs to have traceable history but as a staging environment that can never be treated as complete and I frankly never needed to roll back changes in my knowledgebase, like I usually do in the codebases I work with. So, do with version control as you please and as you see fit for your own purpose.\nThat\u0026rsquo;s it. That\u0026rsquo;s my 20% of effort that gives me 80% of the desired result, which is being able to get to any meaningful sliver of information within fractions of a second and finding links between pieces of related information.\nAlternatives If Obsidian is perfect for you, stop reading this post now. If you looked at Obsidian and still feel like you need something different, then read on. I did my fair share of experimentation with different solutions, I will also list those that I haven\u0026rsquo;t tried as well.\nAs with pretty much everything on this blog, what follows is an opinion piece and you will find that for some of the products I tried I am pretty opinionated. Treat it as just one person\u0026rsquo;s perspective and feel free to make your own about the tools I mention if you feel they would work for your particular use case.\nWhat I tried and can recommend Notion Notion is very similar to Obsidian with the following differences:\nYour notes are kept in the Notion database on a server somewhere. You don\u0026rsquo;t have direct access to the files. Notion has way more team-oriented features. Notion has unparalleled support for tabular data, much more advanced than Obsidian. Notion has a reasonably large user base and good technical support team. When should you choose Notion You need to work with a lot of tabular data. You have little patience for managing files in directories. You find Obsidian\u0026rsquo;s interface less intuitive or if you\u0026rsquo;re not so good with computers. You want to share knowledge for a project with a team and manage tasks in the first place. Why I stopped using Notion I loved the everything is a page and a heavy reliance on tabular databases since it made looking through e.g. tool collections much easier than in Obsidian. But I found search and quick-switch capabilities to be much more important for me. Both tools support these.\nBut I stopped using Notion because I had little control over the data directly. The representation even after exporting the data isn\u0026rsquo;t exactly 100% Markdown which is a very portable format for content creation and distribution and I wanted to absolutely use it over anything else. Their API rollout was also underwhelming which means I couldn\u0026rsquo;t find integrations with other applications that were meaningful to me and developing those integrations myself just wasn\u0026rsquo;t an option when I realized how convoluted their data model must be.\nAnother issue with Notion is the fact that technically although you own the data, they seem to be unencrypted and Notion employees can actually read your content. I would never feel comfortable placing any sensitive data into my Notion knowledgebase.\nOne feature that sold me on Obsidian over Notion in the end was the ability to display knowledge graphs in Obsidian. Knowledge is non-linear and surprisingly software giants that trade in knowledge management systems (e.g. Notion, Atlassian) seem to ignore this fact as if it was nothing. Working with knowledge as a graph forced me to make my notes more atomic and easier to link together which closely corresponds to the way knowledge is stored in a human brain (at least to the extent we know now).\nFoam Foam is a Visual Studio Code extension that enables you to view knowledge graphs and create wiki-links.\nYou get bi-directional links and a graph view very similar to what you get with Obsidian. You can use VSCode for notes which makes a lot of sense if you\u0026rsquo;re using it already for software development. However Foam is pretty simplistic and doesn\u0026rsquo;t go anywhere beyond that. Still in the context of the Pareto principle this might prove to be way more than enough. And the best part: it\u0026rsquo;s entirely open-source and free forever. What I tried and would not recommend Microsoft OneNote It is fairly good as notetaking software and I used it my entire high-school and 3 years of university before software like Notion or Obsidian started appearing on the market. The biggest issues with OneNote for me:\nOpen page concept -\u0026gt; initially I liked the fact that I can click anywhere on the page and arrange content into text-box-like blocks as I please. But for the same reason my notes would always lack consistent structure and one would usually have to scroll over the width and height of the page at the same time to make sense of those huge clumps of information. Abysmal experience while printing pages or exporting to PDF -\u0026gt; I very rarely had to print anything but when I wanted to export my notes to a PDF and share it with other students the output would always be garbled. This issue as far as I know has never been fixed and is related to the fact that it\u0026rsquo;s nearly impossible to represent this open-page format in finitely sized PDF pages. Subpar support for macOS -\u0026gt; I waited years to get the ability to create custom tags in OneNote on a Mac. This is not ok. No Markdown support -\u0026gt; Ctrl+B for bold, Ctrl+I for italics, etc. But then Ctrl+1 for Heading 1, Ctrl+2 for Heading 2\u0026hellip; This is perhaps very nitpicky but hitting ## twice to get the Heading 2 at least doesn\u0026rsquo;t ask me to travel from 1 to 2. My finger automatically lands on the same key when I want to create headings and it\u0026rsquo;s just so much better for muscle memory. It\u0026rsquo;s a shame OneNote doesn\u0026rsquo;t support Markdown. No backlinks -\u0026gt; you get one-way wiki-links. That\u0026rsquo;s it. Clunky interface -\u0026gt; typical Microsoft, i.e. expand a ribbon, click a button, select an option from the menu, click ok\u0026hellip; In Obsidian things like these usually cost two keystrokes. Poor search -\u0026gt; I found the search and quick-switch experience to be vastly subpar to Notion or Obsidian. It\u0026rsquo;s perhaps more about interface than indexing but it just always hampered me from being fast enough. üëÄ Overall, MS OneNote is a really good notetaking tool but a quite poor choice for full-fledged knowledgebase software.\nEvernote Evernote is one of those riches to rags stories. Back in the days of Evernote with an endless tape and just unparalleled search, tagging and sorting experience it was the closest to organized I have ever been. From my perspective Evernote devolved and became outrageously expensive very quickly.\nExtremely expensive for meager set of features -\u0026gt; I pay 50 euros for the Obsidian commercial license (because I wanted to use it at work, otherwise it\u0026rsquo;s free). For a year of Evernote\u0026rsquo;s Personal plan I\u0026rsquo;d have to shell out about 80 euros. Tries to be everything -\u0026gt; Evernote tries to be your main productivity platform and a notetaking application which makes it good at none of those things. It sports task lists, calendars, reminders, OCR search (admittedly this one is top-notch) and a web clipper. Well but here\u0026rsquo;s the deal, dear Evernote. For tasks and reminders I use MS ToDo, for calendars I use iOS Calendar app or MS Outlook, OCR search is something I maybe used twice in the history of using Evernote itself and I stopped clipping websites in 2012. Links are much more efficient in my humble opinion. Performance issues -\u0026gt; last time I used Evernote it was slow, borderline unusable. Since it\u0026rsquo;s a commercial product this probably has been fixed up until now but just be aware that it might not be the snappiest experience. Yet another proprietary format -\u0026gt; you won\u0026rsquo;t find Markdown here either. Atlassian Confluence Oh my goodness, where do I start. I cannot believe that this tool is regarded as the professional knowledgebase software for teams. All my experiences with Confluence up until now have been quite unpleasant and the rigidness of the Atlassian stack leaves a lot to be desired.\nWant a plugin? Sure, give me $10000! -\u0026gt; Confluence has a plugin system. Sadly most of the really useful plugins are outrageously expensive because plugin developers have noticed that there\u0026rsquo;s a lot of money to make. Confluence\u0026rsquo;s philosophy is far from open-source and free stuff. Want Markdown? How about Confluence Wiki Markup? -\u0026gt; Confluence does not use Markdown. Instead they have their own custom markup language that literally no other tool uses. So now instead of learning one markup language, you need to learn two. Expensive -\u0026gt; $5.50 per user per month. It comes out to about 60 euros per year per user. Arguably, Obsidian commercial license is in the ballpark of 50 euros per computer which is close. Confluence is ok as a basic Wiki software for teams but for what it actually gives you it\u0026rsquo;s a ripoff. I often jokingly call this disappointing tool Confusence.\nWhat I haven\u0026rsquo;t tried but might work for you Basecamp -\u0026gt; project management software akin to a combination of Atlassian Confluence and Jira Roam Research -\u0026gt; non-linear notetaking tool with a cult following. Also, quite expensive. Zenkit Hypernotes -\u0026gt; extremely aesthetically pleasing and looks like it\u0026rsquo;s packed with the right number of features but has a hard cap on the limit of notes for almost all of the plans (both free and paid) Fibery -\u0026gt; similar to Notion but with more generative approach to building your own workspace Anytype -\u0026gt; I actually tried it but not enough to formulate a strong opinion about it. It looks similar to Notion but with much more extensible object model, content synchronization using a distributed filesystem (IPFS) and a very reasonable approach to privacy issues. The team also promises that Anytype will always be free and open-source which is absolutely awesome. I tried the early alpha for a short while but it wasn\u0026rsquo;t stable enough to switch to but you should definitely keep an eye on it. Once it\u0026rsquo;s released it might steal a huge chunk of market from tools like Notion. If you have any other suggestions to try out or if you have other perspectives on the tools I mentioned in the article, feel free to throw in a comment.\n","permalink":"http://kjczarne.github.io/2021-12-18-the-most-important-piece-of-advice/","summary":"If were to read only one post from this blog and ignore all the others, here is a piece of advice that I would like to give to everyone who wants to vastly improve their career.\nüëâ The most priceless thing that will help you excel in anything you do is your brain. The second most priceless thing is your second brain.\nWhat I mean by that?\nIf you are able to build a robust reference system with a very short lookup time for any possible piece of information, you will excel at everything you do.","title":"The Most Important Piece of Advice"},{"content":"Sin number 3: Unconditional romance with ducktyping Whence the temptation? Python is truly awesome. In C++17 there is no easy way of expressing ranges. In Python an integer range \\(\\langle 0, 4 \\rangle\\) is simply range(0, 5).\nThe syntactic simplicity and high conciseness of the language was originally related to the fact that Python does not have static typing. In Python ducktyping means that you can actually call a function that expects an integer with a string and you will likely only realize at runtime, since there is no compilation step. It makes coding in Python, well\u0026hellip; very easy to begin with but it comes at a huge cost of bugs appearing in production code.\nWhy is this a sin? Actually, let\u0026rsquo;s make it an example:\ndef add_two_ints(x, y): return x + y If we call this like add_two_ints(2, 2), we will get 4.\nWhat will we get if we invoke add_two_ints(2, \u0026quot;lol\u0026quot;)? Is it even possible? Well, kind of. You can call the function but you will get a runtime error:\nTypeError: unsupported operand type(s) for +: \u0026#39;int\u0026#39; and \u0026#39;str\u0026#39; Adding a 2 to a \u0026quot;lol\u0026quot; string is quite ambiguous and in most cases probably a bug so the interpreter throws an error. But notice that we were able to call the function and there was no type checking happening up to the point of x + y operation.\nIf we tweak this function slightly:\ndef add_two_ints(x, y): print(f\u0026#34;x is {x}, y is {y}\u0026#34;) return x + y The print will run just fine and give us \u0026quot;x is 2, y is 2\u0026quot;! So the input was not checked in any way before the function body has been executed.\nThe example is trivial. But as your code expands, these problems will grow out of control very quickly. We should have a way of controlling the types of input values we\u0026rsquo;re invoking the function with.\nHow to recognize a sinner? Sinners will use bare Python without type hints (which we\u0026rsquo;ll discuss as a solution in the next section) or in the worst instance no facilities for type checking. To make it clearer:\nBad solution The exact example we used originally is a prime example of the worst solution possible:\ndef add_two_ints(x, y): return x + y Slightly better solution A slightly improved variant would actually check the types of arguments at runtime:\ndef add_two_ints(x, y): if type(x) is not int and type(y) is not int: raise ValueError(f\u0026#34;This function accepts only integers as parameters! Called with {x} and {y}\u0026#34;) return x + y However when writing code in any modern editor (e.g. VSCode with Pylance Server or JetBrains PyCharm), the language analyzer will not catch any bad invocations as you write your code. You have to run it to see where it fails and that\u0026rsquo;s suboptimal in terms of development speed and it tends to get very frustrating.\nIf you place the following somewhere else in your code, perhaps in a different module where you import your brand new add_two_ints function:\nadd_two_ints(2, \u0026#34;lol\u0026#34;) Your editor will not tell you that you\u0026rsquo;re using the wrong arguments until you run the script.\nHow to repent? There is one extremely important feature that has been added in Python 3.5 and solves the aforementioned problem: type hints. The advantage of using type hints over bare runtime checking is that you can catch type mismatch issues before you run your code. First you would have to refactor the function slightly:\ndef add_two_ints(x: int, y: int) -\u0026gt; int: if type(x) is not int and type(y) is not int: raise ValueError(f\u0026#34;This function accepts only integers as parameters! Called with {x} and {y}\u0026#34;) return x + y This gives you the following benefits:\nadd_two_ints(x: int, y: int) -\u0026gt; int describes the entire signature of the function. Most analysis services like the Python Language Server in VSCode will be able to suggest you what type the input parameters are while you\u0026rsquo;re coding. The aforementioned Language Server will also display a red squiggle under each parameter that is of an unexpected type, hence it will notify you of mistakes like add_two_ints(2, \u0026quot;lol\u0026quot;) while you\u0026rsquo;re coding. You can force every contributor to use type hints where they\u0026rsquo;re required by using static type checkers like pyright by running this in your code acceptance pipelines. Important question: does this absolve me from runtime parameter checking? Well, it doesn\u0026rsquo;t prevent anyone from still conjuring deamons like add_two_ints(2, \u0026quot;lol\u0026quot;) but at least it will give them a hint if they themselves use something that comes at least close to what VSCode+Pylance can provide.\nIn the end my recommendations would be:\nüëâ Use type hints aggressively. Invest ample time into learning about type aliases, hints for generics, etc. There is a lot of resources out there but if you want a fairly condensed overview, throw in a comment and I\u0026rsquo;ll share my own reference sheet. Good news: it\u0026rsquo;s so easy and intuitive that it will enter your muscle memory within a few days.\nüëâ Use VSCode with the Pylance Python Language Server. It understands type hints and tells you right away when you\u0026rsquo;re attempting something you shouldn\u0026rsquo;t be doing. Or really just use any other IDE or editor that understands type hints.\nüëâ If you want to be absolutely certain that whoever uses your code doesn\u0026rsquo;t pass a wrong parameter, use runtime type checking and throw informative errors to let the user understand where the error came from.\nüëÄ Trust me when I say this: you wouldn\u0026rsquo;t believe how many bugs having static type information is able to catch. When you\u0026rsquo;re typing for hours on end you will get tired. You will overlook things. You will get distracted. If you really want high-quality code that will be easier to maintain, use every possibility to be your own adversary and try to catch your own mistakes.\nWhile it\u0026rsquo;s lately become a controversial topic to exactly quantify how much more catching a bug in production than in development costs, there have been some ridiculous examples of bugs costing companies hundreds of millions of dollars. Pareto principle definitely applies here, putting too many safeguards into your code acceptance pipeline may actually decrease productivity if you go overboard. Type hints however gave me personally the biggest bang for the buck when it comes to code quality assurance, that\u0026rsquo;s why I am so bullish on them.\n","permalink":"http://kjczarne.github.io/2021-12-17-seven-sins-of-python-sin-3/","summary":"Sin number 3: Unconditional romance with ducktyping Whence the temptation? Python is truly awesome. In C++17 there is no easy way of expressing ranges. In Python an integer range \\(\\langle 0, 4 \\rangle\\) is simply range(0, 5).\nThe syntactic simplicity and high conciseness of the language was originally related to the fact that Python does not have static typing. In Python ducktyping means that you can actually call a function that expects an integer with a string and you will likely only realize at runtime, since there is no compilation step.","title":"Seven Sins of Python - Sin 3"},{"content":"Here are links to some of the Jupyter Notebooks mentioned in my blog posts:\nPython - timing builtins vs. loops ","permalink":"http://kjczarne.github.io/nb/","summary":"Here are links to some of the Jupyter Notebooks mentioned in my blog posts:\nPython - timing builtins vs. loops ","title":"Notebooks"},{"content":"Sin number 2: too few optimized functions used This one is pretty common especially for newcomers who have learnt enough about Python to be able to loop over data structures but haven\u0026rsquo;t yet realized how slow Python loops really are.\nWhence the temptation? If you\u0026rsquo;re fresh to Python, the temptation to create for loops everywhere for lists and dictionaries is immense. Consider a fairly simple example, where we loop over 100000 random integers and we apply a simple mathematical operation to each of those integers. The most straightforward solution would be:\nfor i in random_integers: out_list.append(perform_predefined_calculation(i)) (assumming here that perform_predefined_calculation and random_integer exist)\nA slightly more Pythonic way to express this would be:\nout_list = [perform_predefined_calculation(i) for i in random_integers] Why is this a sin? While it might be ok for small data structures, the problem with all kinds of loops in Python is that they\u0026rsquo;re pretty slow in comparison with functional constructs such as map or filter. Why is that? Python is an interpreted language, so every statement is evaluated at runtime, there is no compilation process. But functions like map and filter were actually implemented in C (well, at least if you\u0026rsquo;re using the most widespread CPython) and C code can be, well\u0026hellip; pretty fast.\nThe test I\u0026rsquo;ve ran showed about 30% performance increase with a simple refactor from a for loop to a list(map(f, x)) idiom.\nYou can do your own timings on your own and modify the examples as you please in this Python notebook.\nHow to recognize a sinner? Our sinners will most likely be individuals less experienced with Python and can be recognized by profilic abuse of loops whenever working with iterable data structures. Every professional will also often use for and less often while, however performance-critical parts of code where a large amount of data is expected will almost always be brimming with the functional idioms.\nHow to repent? It\u0026rsquo;s okay to use for and while but not where you need fast code. Learn to use at least map, filter and functools.reduce. Refactor code that iderates over large data structures to use the aforementioned functions. In our particular example, the repentance is easy and gives us code nearly as pretty as the list comprehension used before:\nout_list = list(map(perform_predefined_calculation, random_integers)) üëÄ map applies perform_predefined_calculation function to each element of the random_integers list. map is lazy so it will only run when we iterate over the result at some point. To load the output as a standard Python list, we can simply wrap it into a list() call. The output will be thus exactly the same as originally but we\u0026rsquo;ll be able to obtain it much faster.\n","permalink":"http://kjczarne.github.io/2021-12-16-seven-sins-of-python-sin-2/","summary":"Sin number 2: too few optimized functions used This one is pretty common especially for newcomers who have learnt enough about Python to be able to loop over data structures but haven\u0026rsquo;t yet realized how slow Python loops really are.\nWhence the temptation? If you\u0026rsquo;re fresh to Python, the temptation to create for loops everywhere for lists and dictionaries is immense. Consider a fairly simple example, where we loop over 100000 random integers and we apply a simple mathematical operation to each of those integers.","title":"Seven Sins of Python - Sin 2"},{"content":"I am a Software Developer at Technica Engineering GmbH with a focus on process automation, continuous integration systems and infrastructure tooling. I am currently involved in projects related to the automation of hardware testing in the automotive domain. I speak Python, C#, F#, TypeScript and to a lesser degree Rust. I despise C++.\nMy original domain is Biotechnology with focus on Genetics and Epigenetics. I have a B.Sc. degree in Biotechnology and am an alumnus of Data Science Retreat Deep Learning Bootcamp.\nI am pretty sure I have Asperger\u0026rsquo;s or something of that sort but nobody dared diagnose me yet. üòÇ\n","permalink":"http://kjczarne.github.io/about/","summary":"I am a Software Developer at Technica Engineering GmbH with a focus on process automation, continuous integration systems and infrastructure tooling. I am currently involved in projects related to the automation of hardware testing in the automotive domain. I speak Python, C#, F#, TypeScript and to a lesser degree Rust. I despise C++.\nMy original domain is Biotechnology with focus on Genetics and Epigenetics. I have a B.Sc. degree in Biotechnology and am an alumnus of Data Science Retreat Deep Learning Bootcamp.","title":"About Me"},{"content":"Sin number 1: Do not modify builtins and globals This is one of the biggest no-nos for me and something that I shot myself in the foot at least twice in my career as a Python dev. I\u0026rsquo;ve also seen this used in actual production code that was deployed to some important clients.\nWhence the temptation? builtins is a collection of objects that are available from within any Python script and are loaded before any script is executed by the interpreter. If you\u0026rsquo;ve ever used int, bytes, dict, list, etc. then these all come from builtins. globals is a collection of objects that exist in current global scope, so objects accessible to any module at a particular point in time when your script is running. üëâ It is tempting to modify the builtins to expose a particular custom function or object globally to any running Python script without the need to import a module explicitly. Likewise the modification of globals can enable such magic as dynamic imports of modules that are a part of the same package without actually using the explicit module names.\nWhy is this a sin? In both cases it makes your code less explicit and modifies global interpreter behavior after builtins or globals have been modified. The implications of this are:\nNobody understands your code -\u0026gt; you\u0026rsquo;re using symbols that were sneakily imported at some point but no person using your code will be able to easily tell what module they came from and what they do. It often breaks code suggestions -\u0026gt; implicilty imported stuff may not be picked up by language analysis tools that try to determine the validity of statements in your code. It creates a potential for name collisions -\u0026gt; if you were to e.g. define your own map function and then tried adding it to builtins you could inadvertently override a built-in map function. Such blunders are extremely hard to debug. How to recognize a sinner? The following example function walks two steps into an src submodule and looks for classes that are subclasses of ImportMe and ImportMeToo. It then adds them to globals, which can be used in current scope.\ndef walking_import(): from mod import src for _, name, _ in pkgutil.walk_packages(src.__path__): _temp = importlib.import_module(src.__package__ + \u0026#39;.\u0026#39; + name) for _, n, _ in pkgutil.walk_packages(_temp.__path__): _temp2 = importlib.import_module(_temp.__package__ + \u0026#39;.\u0026#39; + n) for n2, m in inspect.getmembers(_temp2, inspect.isclass): if issubclass(m, ImportMe) or issubclass(m, ImportMeToo): globals()[n2] = m return globals() This is a real function (though slightly redacted) that I once put into production code. A few weeks later we had to change the import sequence in the entire package back to what it used to be because modifying globals made IntelliSense useless and nobody could make sense of the code.\nHow to repent? My advice: never modify globals or builtins. If you find yourself doing that then probably something is fundamentally wrong with the design of your application. If you\u0026rsquo;re a novice make sure to consult your application design with somebody who has more experience. Prefer explicit imports and as little import magic as possible.\nüëÄ Where import magic was usually useful for me was when I wanted to load entire Python scripts as configuration files. Even though I would use importlib and inspect modules for that, I would never touch globals or builtins.\n","permalink":"http://kjczarne.github.io/2021-12-10-seven-sins-of-python-sin-1/","summary":"Sin number 1: Do not modify builtins and globals This is one of the biggest no-nos for me and something that I shot myself in the foot at least twice in my career as a Python dev. I\u0026rsquo;ve also seen this used in actual production code that was deployed to some important clients.\nWhence the temptation? builtins is a collection of objects that are available from within any Python script and are loaded before any script is executed by the interpreter.","title":"Seven Sins of Python - Sin 1"},{"content":"Seven Sins of Python - intro Python is not only the most popular programming language (according to TIOBE as of 2021) but also one of the simplest to work with and easiest to learn. Python is great for a wide range of applications from web development through command line tools to large-scale automation and deep learning projects.\nIt is far from the snappiest programming languages in terms of performance, however many other languages can be used alongside Python when performance is of essence.\nBecause it\u0026rsquo;s so easy to do anything in Python, it\u0026rsquo;s also incredibly easy to do things that are at best slight stumbles and at worst critical design mistakes that may make any project unmaintainable and even unstable in the long run. As someone who codes predominantly in Python, I\u0026rsquo;ve seen some terrible patterns used in commercial products but I\u0026rsquo;ve also had the misfortune of becoming a victim of a few of those myself.\nThis series describes what I think are the 7 biggest mistakes that could be a part of any application. In my humble opinion, you should avoid these at all cost. As with all cults, this is one prophet\u0026rsquo;s gospel. You might find yourself disagreeing with one or more of these statements, perhaps even all of them. That\u0026rsquo;s ok.\nHow to read the series articles Each section that follows will be split up into clear components:\nWhence the temptation? -\u0026gt; explains why developers tend to use a particular antipattern Why is this a sin? -\u0026gt; explains why a particular practice is an antipattern How to recognize a sinner? -\u0026gt; provides an example of the antipattern How to repent? -\u0026gt; provides a better alternative to the antipattern ","permalink":"http://kjczarne.github.io/2021-12-10-seven-sins-of-python-intro/","summary":"Seven Sins of Python - intro Python is not only the most popular programming language (according to TIOBE as of 2021) but also one of the simplest to work with and easiest to learn. Python is great for a wide range of applications from web development through command line tools to large-scale automation and deep learning projects.\nIt is far from the snappiest programming languages in terms of performance, however many other languages can be used alongside Python when performance is of essence.","title":"Seven Sins of Python - Intro"}]